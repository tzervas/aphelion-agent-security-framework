[
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "dill",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dill",
        "description": "dill",
        "detail": "dill",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "StringIO",
        "description": "StringIO",
        "detail": "StringIO",
        "documentation": {}
    },
    {
        "label": "pands",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pands",
        "description": "pands",
        "detail": "pands",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Object",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "Object2",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "Object3",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "lib1",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib2",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib3",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib4",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib5",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib6",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib7",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib8",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib9",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib10",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib11",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib12",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib13",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib14",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib15",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "google.protobuf.descriptor_pb2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.protobuf.descriptor_pb2",
        "description": "google.protobuf.descriptor_pb2",
        "detail": "google.protobuf.descriptor_pb2",
        "documentation": {}
    },
    {
        "label": "Bar",
        "importPath": "source",
        "description": "source",
        "isExtraImport": true,
        "detail": "source",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "pairwise",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "islice",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "jwt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jwt",
        "description": "jwt",
        "detail": "jwt",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "JWTConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "AppConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "JWTConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "AppConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "JWTConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "LoggingConfigModel",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_FILE",
        "importPath": "aphelion.config",
        "description": "aphelion.config",
        "isExtraImport": true,
        "detail": "aphelion.config",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "SecretStr",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "field_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "SecretStr",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseSettings",
        "importPath": "pydantic_settings",
        "description": "pydantic_settings",
        "isExtraImport": true,
        "detail": "pydantic_settings",
        "documentation": {}
    },
    {
        "label": "SettingsConfigDict",
        "importPath": "pydantic_settings",
        "description": "pydantic_settings",
        "isExtraImport": true,
        "detail": "pydantic_settings",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "create_access_token",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "create_refresh_token",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "decode_token",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "validate_token",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "# JWTConfig",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "# This is now JWTConfigModel from aphelion.config\r\n    # configure_jwt",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "# This is removed\r\n    InvalidTokenError",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "ExpiredTokenError",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "MissingTokenError",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "RevokedTokenError",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "revoke_token",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "is_token_revoked",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "clear_revoked_tokens_store # New helper for test cleanup\r\n    # _jwt_config",
        "importPath": "aphelion.auth.jwt",
        "description": "aphelion.auth.jwt",
        "isExtraImport": true,
        "detail": "aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "given",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "strategies",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "HealthCheck",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "get_greeting",
        "importPath": "aphelion.main",
        "description": "aphelion.main",
        "isExtraImport": true,
        "detail": "aphelion.main",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "def run_command(cmd):\n    \"\"\"\n    Execute a shell command and return its exit code, stdout, and stderr.\n    Args:\n        cmd: List of command arguments to execute\n    Returns:\n        Tuple containing (return_code, stdout, stderr)\n    \"\"\"\n    try:\n        process = subprocess.Popen(",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "update_cmd",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "update_cmd = [\"terraform-docs\", \".\"]\nreturn_code, stdout, stderr = run_command(update_cmd)\nif stderr:\n    print(f\"terraform-docs error: Warning during execution:\\n{stderr}\", file=sys.stderr)\n# Check git status for unstaged README changes\nstatus_cmd = [\"git\", \"status\", \"--porcelain\"]\nreturn_code, stdout, stderr = run_command(status_cmd)\n# Look for any README.md files in the unstaged changes\nunstaged_readmes = [\n    line.split()[-1]",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "status_cmd",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "status_cmd = [\"git\", \"status\", \"--porcelain\"]\nreturn_code, stdout, stderr = run_command(status_cmd)\n# Look for any README.md files in the unstaged changes\nunstaged_readmes = [\n    line.split()[-1]\n    for line in stdout.splitlines()\n    if line.startswith(\" M\") and line.endswith(\"README.md\")\n]\n# Check if we found any unstaged README files\nif len(unstaged_readmes) > 0:",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "unstaged_readmes",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "unstaged_readmes = [\n    line.split()[-1]\n    for line in stdout.splitlines()\n    if line.startswith(\" M\") and line.endswith(\"README.md\")\n]\n# Check if we found any unstaged README files\nif len(unstaged_readmes) > 0:\n    print(\"terraform-docs error: Please stage any README changes before committing.\")\n    sys.exit(1)\nprint(\"terraform-docs: Documentation is up to date\")",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "Example3",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "class Example3(   object ):\n    def __init__    ( self, bar ):\n     #Comments should have a space after the hash.\n     if bar : bar+=1;  bar=bar* bar   ; return bar\n     else:\n                    some_string = \"\"\"\n                       Indentation in multiline strings should not be touched.\nOnly actual code should be reindented.\n\"\"\"\n                    return (sys.path, some_string)",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "example1",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "def example1():\n    ####This is a long comment. This should be wrapped to fit within 72 characters.\n    some_tuple=(   1,2, 3,'a'  );\n    some_variable={'long':'Long code lines should be wrapped within 79 characters.',\n    'other':[math.pi, 100,200,300,9876543210,'This is a long string that goes on'],\n    'more':{'inner':'This whole logical line should be wrapped.',some_tuple:[1,\n    20,300,40000,500000000,60000000000000000]}}\n    return (some_tuple, some_variable)\ndef example2(): return {'has_key() is deprecated':True}.has_key({'f':2}.has_key(''));\nclass Example3(   object ):",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "example2",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "def example2(): return {'has_key() is deprecated':True}.has_key({'f':2}.has_key(''));\nclass Example3(   object ):\n    def __init__    ( self, bar ):\n     #Comments should have a space after the hash.\n     if bar : bar+=1;  bar=bar* bar   ; return bar\n     else:\n                    some_string = \"\"\"\n                       Indentation in multiline strings should not be touched.\nOnly actual code should be reindented.\n\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "pick",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "peekOfCode": "pick = dill.dumps({\"a\": \"b\", \"c\": \"d\"})\nprint(dill.loads(pick))\nfile_obj = StringIO.StringIO()\ndill.dump([1, 2, \"3\"], file_obj)",
        "detail": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "file_obj",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "peekOfCode": "file_obj = StringIO.StringIO()\ndill.dump([1, 2, \"3\"], file_obj)",
        "detail": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"\ncachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\nimport pands\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "cachedir",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "cachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "description": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "description": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "peekOfCode": "def main(argv):\n    results = []\n    for line in sys.stdin.readlines():\n        filename, line_number, message = line.split(\":\")\n        results.append(\n            to_result_sarif(\n                filename, int(line_number), 0, \"misspelled\", message.strip()\n            )\n        )\n    sarif = {",
        "detail": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"\ncachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\nimport pands\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "cachedir",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "cachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\n# trunk-ignore(flake8/F401): this will trigger a warning to verify that the config is applied\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "aws_access_key_id = \"AKIAIO5FODNN7EXAMPLE\"\naws_token = \"AKIALALEMEL33243OLIA\"\nprivate_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "aws_token",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "aws_token = \"AKIALALEMEL33243OLIA\"\nprivate_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "private_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "private_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "description": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "peekOfCode": "def to_result_sarif(path: str, lineno: int, colno: int, rule_id: str, message: str):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "description": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "peekOfCode": "def main(argv):\n    output_json = json.load(sys.stdin)\n    errors = output_json.get(\"errors\", [])\n    results = []\n    for error in errors:\n        rule = error.get(\"rule\", \"\")\n        message = error.get(\"message\", \"\")\n        location = error.get(\"location\")\n        if location:\n            path = location.get(\"file\", \"\")",
        "detail": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "documentation": {}
    },
    {
        "label": "try_find_string_in_file",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def try_find_string_in_file(filename, search_string):\n    with open(filename, \"r\") as f:\n        for i, line in enumerate(f):\n            index = line.find(search_string)\n            if index != -1:\n                return i + 1, index + 1\n    return 0, 0\ndef to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def main(argv):\n    parser = argparse.ArgumentParser(description=\"Parse output of markdown-link-check\")\n    parser.add_argument(\"--target\", dest=\"target\")\n    args = parser.parse_args()\n    results = []\n    # Line numbers are not reported out of the tool right now - so we regex parse the output to extract issue codes\n    for line in sys.stdin:\n        parse_reg = \"\\s*(\\[.*\\])\\s(.*)→.*Status:\\s*(\\d*)(.*)\"\n        filename = args.target\n        parse_result = re.fullmatch(parse_reg, line, flags=re.DOTALL)",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "greeting",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def greeting(name: str) -> str:\n    return \"Hello \" + name\ndef printer() -> None:\n    print(\"Hello\")\ngreeting(3)\ngreeting(b\"Alice\")\na = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "printer",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def printer() -> None:\n    print(\"Hello\")\ngreeting(3)\ngreeting(b\"Alice\")\na = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "bad_foo",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "a = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "peekOfCode": "class Bar:\n  a: int\n  b: int\ndef bad_function() -> int:\n  print(\"returns nothing\")",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "documentation": {}
    },
    {
        "label": "bad_function",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "peekOfCode": "def bad_function() -> int:\n  print(\"returns nothing\")",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.nancy.parse",
        "description": ".trunk.plugins.trunk.linters.nancy.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.nancy.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.nancy.parse",
        "description": ".trunk.plugins.trunk.linters.nancy.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    nancy_output = json.load(sys.stdin)\n    for vuln_entry in nancy_output.get(\"vulnerable\", []):\n        for vuln in vuln_entry.get(\"Vulnerabilities\", []):\n            results.append(\n                to_result_sarif(\n                    \".\",\n                    0,\n                    0,",
        "detail": ".trunk.plugins.trunk.linters.nancy.parse",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"database_specific\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    vuln_metadata = vuln[\"database_specific\"]\n    if \"severity\" not in vuln_metadata:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln_metadata[\"severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, lineno: int, vuln_id: str, description: str, severity: str\n):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "join_common_sets",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def join_common_sets(lst):\n    init_len = 0\n    final_len = 1\n    while init_len != final_len:\n        init_len = len(lst)\n        ret = []\n        for s in lst:\n            unique = True\n            for stored_set in ret:\n                if len(stored_set.intersection(s)) > 0:",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_preferred_alias",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def get_preferred_alias(aliases):\n    for rx in PREFERRED_ORDER:\n        found_aliases = sorted(alias for alias in aliases if re.match(rx, alias))\n        if len(found_aliases) > 0:\n            return found_aliases[0]\n    return sorted(aliases)[0]\ndef main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.\n        if sys.platform == \"win32\":",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.\n        if sys.platform == \"win32\":\n            filtered_stdin = \"\".join(i for i in sys.stdin.read() if ord(i) < 256)\n            osv_json = json.loads(filtered_stdin)\n        else:\n            osv_json = json.load(sys.stdin)\n    except json.decoder.JSONDecodeError as err:\n        if str(err) == \"Expecting value: line 1 column 1 (char 0)\":",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"database_specific\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    vuln_metadata = vuln[\"database_specific\"]\n    if \"severity\" not in vuln_metadata:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln_metadata[\"severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "PREFERRED_ORDER",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "PREFERRED_ORDER = [\"GHSA-.*\", \"CVE-.*\", \"PYSEC-.*\"]\ndef get_preferred_alias(aliases):\n    for rx in PREFERRED_ORDER:\n        found_aliases = sorted(alias for alias in aliases if re.match(rx, alias))\n        if len(found_aliases) > 0:\n            return found_aliases[0]\n    return sorted(aliases)[0]\ndef main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "description": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "peekOfCode": "def main():\n    phpstan_json = json.loads(sys.stdin.read())\n    results = []\n    for file_name in phpstan_json[\"files\"]:\n        file_result = phpstan_json[\"files\"][file_name]\n        for result in file_result[\"messages\"]:\n            result = {\n                # We do not have a ruleId\n                \"message\": {\n                    \"text\": result[\"message\"],",
        "detail": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "description": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, description: str, line: int = 0, column: int = 0):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "description": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "peekOfCode": "def main(argv):\n    if len(argv) < 2:\n        print(\"Usage: trivy_to_sarif.py <exit_code>)\")\n        sys.exit(1)\n    if argv[1] == \"0\":\n        results = []\n        sarif = {\n            \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n            \"version\": \"2.1.0\",\n            \"runs\": [{\"results\": results}],",
        "detail": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "documentation": {}
    },
    {
        "label": "shift",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "shift = 3\nchoice = raw_input(\"would you like to encode or decode?\")\nword = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "choice",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "choice = raw_input(\"would you like to encode or decode?\")\nword = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "word",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "word = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "letters",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "letters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "encoded",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "encoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "foo",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "peekOfCode": "def foo():\n    return \"bar\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\" # Mypy treats this as an error because `x` is implicitly declared as `int`\na = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error\nclass Color(Enum):\n    RED = 1",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Color",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class Color(Enum):\n    RED = 1\n    BLUE = 2\ndef is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\n    # mypy reports error: Missing return statement\ndef func(val: int | None):",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "wrong_type",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def wrong_type(x: int) -> str:\n    return x  # error: Incompatible return value type (got \"int\", expected \"str\")\nclass A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\" # Mypy treats this as an error because `x` is implicitly declared as `int`\na = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "is_red",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\n    # mypy reports error: Missing return statement\ndef func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "func",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)  # mypy produces a false positive error here\n        inner_2 = lambda: reveal_type(val) + 1\n        inner_1()\n        inner_2()",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error\nclass Color(Enum):",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "description": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "peekOfCode": "results = []\nfor result in json.load(sys.stdin)[\"generalDiagnostics\"]:\n    parse = {\n        \"level\": result[\"severity\"] if result[\"severity\"] != \"information\" else \"note\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": result[\"file\"],\n                    },",
        "detail": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "description": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "description": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "description": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    content_json = sys.stdin.read()\n    content = json.loads(content_json)\n    for file_content in content:\n        messages = file_content.get(\"messages\", [])\n        if messages:\n            for msg in messages:\n                results.append(\n                    to_result_sarif(",
        "detail": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.renovate.parse",
        "description": ".trunk.plugins.trunk.linters.renovate.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.renovate.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.renovate.parse",
        "description": ".trunk.plugins.trunk.linters.renovate.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    content = sys.stdin.read()\n    parse_reg = \"(.*WARN:.*could not be parsed)(.*)\"\n    error_section = content.find('\"errors\": [')\n    parse_result = re.fullmatch(parse_reg, content, flags=re.DOTALL)\n    if parse_result:\n        warn_section = parse_result.group(2)\n        json_content = \"{\" + warn_section + \"}\"\n        error_output = json.loads(json_content)",
        "detail": ".trunk.plugins.trunk.linters.renovate.parse",
        "documentation": {}
    },
    {
        "label": "map_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "def map_severity(severity):\n    if severity in [\"convention\", \"refactor\", \"info\"]:\n        return \"note\"\n    if severity in [\"warning\"]:\n        return \"warning\"\n    if severity in [\"error\", \"fatal\"]:\n        return \"error\"\n    return \"none\"\nresults = []\nfor file in json.load(sys.stdin)[\"files\"]:",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "results = []\nfor file in json.load(sys.stdin)[\"files\"]:\n    for offense in file[\"offenses\"]:\n        parse = {\n            \"level\": map_severity(offense[\"severity\"]),\n            \"locations\": [\n                {\n                    \"physicalLocation\": {\n                        \"artifactLocation\": {\n                            \"uri\": file[\"path\"],",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\n# trunk-ignore(ruff/F401)\nimport json\nimport sys\nclass NoDocstring(object):\n    def __init__(self, arg1):",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "peekOfCode": "def f(): {",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "documentation": {}
    },
    {
        "label": "get_region",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "def get_region(entry, column_offset=0):\n    location = entry[\"location\"]\n    region = {\n        \"startColumn\": location[\"column\"] + column_offset,\n        \"startLine\": location[\"row\"],\n    }\n    if \"end_location\" in entry:\n        end_location = entry[\"end_location\"]\n        region[\"endColumn\"] = end_location[\"column\"] + column_offset\n        region[\"endLine\"] = end_location[\"row\"]",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "results = []\ndef get_region(entry, column_offset=0):\n    location = entry[\"location\"]\n    region = {\n        \"startColumn\": location[\"column\"] + column_offset,\n        \"startLine\": location[\"row\"],\n    }\n    if \"end_location\" in entry:\n        end_location = entry[\"end_location\"]\n        region[\"endColumn\"] = end_location[\"column\"] + column_offset",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "ruff_column_index",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "ruff_column_index = 1\nif len(sys.argv) > 1:\n    ruff_column_index = int(sys.argv[1])\nfor result in json.load(sys.stdin):\n    # As of ruff v0.0.260, some autofixable diagnostics may appear redundantly\n    if \"location\" not in result:\n        continue\n    filepath = result[\"filename\"]\n    # Ruff will set code to null for syntax errors\n    rule_id = result[\"code\"] or \"E999\"",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "unvalidated_value",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "description": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "peekOfCode": "def unvalidated_value(request):\n    value = request.GET.get('something')\n    function = globals().get(value)\n    if function:\n        return function(request)",
        "detail": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "peekOfCode": "def test():\n  substitution = \"hello %s\" % test\n  my_list = List()\n  try:\n    pass\n  except Exception:\n    raise Exception(\"test\")",
        "detail": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "peekOfCode": "test = \"world\"\ndef test():\n  substitution = \"hello %s\" % test\n  my_list = List()\n  try:\n    pass\n  except Exception:\n    raise Exception(\"test\")",
        "detail": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str,\n    start_line_number: int,\n    start_column_number: int,\n    end_line_number: Optional[int],\n    end_column_number: Optional[int],\n    rule_id: str,\n    message: str,\n):\n    region = {",
        "detail": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "peekOfCode": "def main(argv):\n    sqlfluff_json = json.load(sys.stdin)\n    results = []\n    for result in sqlfluff_json:\n        filepath = result[\"filepath\"]\n        for violation in result[\"violations\"]:\n            # In sqlfluff 3.0.0, line_no/line_pos replaced with start_*/end_*\n            start_line_number = violation.get(\"start_line_no\", violation.get(\"line_no\"))\n            start_column_number = violation.get(\n                \"start_line_pos\", violation.get(\"line_pos\")",
        "detail": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "description": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "peekOfCode": "def main(argv):\n    input_sarif = json.load(sys.stdin)\n    # strip \"file:\" from the beginning of each value in the 'file' field in the 'location' object in sarif format\n    for run in input_sarif[\"runs\"]:\n        for result in run[\"results\"]:\n            for location in result[\"locations\"]:\n                location[\"physicalLocation\"][\"artifactLocation\"][\"uri\"] = location[\n                    \"physicalLocation\"\n                ][\"artifactLocation\"][\"uri\"][5:]\n    print(json.dumps(input_sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.tfsec.parse",
        "description": ".trunk.plugins.trunk.linters.tfsec.parse",
        "peekOfCode": "def main():\n    original_input = sys.stdin.read()\n    try:\n        index = original_input.index(\"{\")\n        print(original_input[index:])\n    except ValueError:\n        print(original_input)\nif __name__ == \"__main__\":\n    main()",
        "detail": ".trunk.plugins.trunk.linters.tfsec.parse",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "aws_access_key_id = \"AKIAXYZDQCEN4EXAMPLE\"\naws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "aws_secret_access_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "aws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "github_secret",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "github_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "basic_auth",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "basic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "priv_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "priv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5\nWAi47VMFTkDZYS/eCvG53q9UBHpCj7Qvb0vSkCZXBvBIhlw193F3PX4WvO1IXsMwvQ1D1X",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, vuln_id: str, description: str, line: int = 0):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    path = trivy_json[\"ArtifactName\"]\n    results = []\n    for result in trivy_json.get(\"Results\", []):\n        if \"Misconfigurations\" not in result:\n            continue\n        for vuln in result[\"Misconfigurations\"]:\n            vuln_id = vuln[\"ID\"]\n            message = vuln[\"Message\"]",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in secret:\n        return DEFAULT_SARIF_SEVERITY\n    severity = secret[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,\n        \"locations\": [",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    results = []\n    for result in trivy_json.get(\"Results\", []):\n        path = trivy_json[\"ArtifactName\"]\n        for secret in result.get(\"Secrets\", []):\n            code = secret[\"RuleID\"]\n            description = secret[\"Title\"]\n            lineno = secret.get(\"StartLine\", 0)\n            results.append(",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in secret:\n        return DEFAULT_SARIF_SEVERITY\n    severity = secret[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):\n    return {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    results = []\n    lockfiles = {}\n    for result in trivy_json.get(\"Results\", []):\n        for vuln in result.get(\"Vulnerabilities\", []):\n            pkg_name = vuln[\"PkgName\"]\n            path = trivy_json[\"ArtifactName\"]\n            vuln_id = vuln[\"VulnerabilityID\"]\n            description = vuln[\"Title\"]",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "aws_access_key_id = \"AKIAXYZDQCEN4EXAMPLE\"\naws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "aws_secret_access_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "aws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "github_secret",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "github_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "basic_auth",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "basic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "priv_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "priv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5\nWAi47VMFTkDZYS/eCvG53q9UBHpCj7Qvb0vSkCZXBvBIhlw193F3PX4WvO1IXsMwvQ1D1X",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, line_number: int, vuln_id: str, description: str):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "sliding_window",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def sliding_window(iterable, n):\n    # sliding_window('ABCDEFG', 4) --> ABCD BCDE CDEF DEFG\n    it = iter(iterable)\n    window = collections.deque(islice(it, n - 1), maxlen=n)\n    for x in it:\n        window.append(x)\n        yield tuple(window)\nsecret_lineno_cache = {}\nfile_cache = {}\ndef find_line_number(secret, path):",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "find_line_number",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):\n        # trufflehog can report the same secret multiple times\n        # if it truly appears multiple times, then we want to log different lines for each issue",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def main(argv):\n    results = []\n    for line in sys.stdin.readlines():\n        vuln_json = json.loads(line)\n        # trufflehog doesn't have vuln IDs\n        # this is the name of the detector that found the error (e.g. AWS, Github, PrivateKey)\n        vuln_id = vuln_json[\"DetectorName\"]\n        # There also isn't description of the error aside from the raw secret, the redacted secret,\n        # and the detector that found it.\n        #",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "secret_lineno_cache",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "secret_lineno_cache = {}\nfile_cache = {}\ndef find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "file_cache",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "file_cache = {}\ndef find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):\n        # trufflehog can report the same secret multiple times",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\"\na = A()\nreveal_type(a.x)\na.x = \"\"\na.x = 3.0\nclass A:",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)\nclass Color(Enum):\n    RED = 1",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Color",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class Color(Enum):\n    RED = 1\n    BLUE = 2\ndef is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\ndef func(val: int | None):\n    if val is not None:",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "wrong_type",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def wrong_type(x: int) -> str:\n    return x  # error: Incompatible return value type (got \"int\", expected \"str\")\nclass A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\"\na = A()\nreveal_type(a.x)\na.x = \"\"",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "is_red",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\ndef func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "func",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)\n        inner_2 = lambda: reveal_type(val) + 1\n        inner_1()\n        inner_2()",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a = A()\nreveal_type(a.x)\na.x = \"\"\na.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a.x = \"\"\na.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)\nclass Color(Enum):",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n#whitespace below vvv\n  #A malindented comment\nif __name__ == \"__main__\" :\n      a=4+1",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n#whitespace below vvv\n  #A malindented comment\nif __name__ == \"__main__\" :\n      a=4+1\n      b=( 2*7 )\n      c = [1,\n           2,",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\n# trunk-ignore(flake8/F401): this will trigger a warning to verify that the config is applied\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "MissingTokenError",
        "kind": 6,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "class MissingTokenError(Exception):\n    \"\"\"Raised when a token is expected but not found.\"\"\"\n    pass\nclass InvalidTokenError(Exception):\n    \"\"\"Raised when a token is invalid (e.g., malformed, wrong signature).\"\"\"\n    pass\nclass ExpiredTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has expired.\"\"\"\n    pass\nclass RevokedTokenError(InvalidTokenError):",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "InvalidTokenError",
        "kind": 6,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "class InvalidTokenError(Exception):\n    \"\"\"Raised when a token is invalid (e.g., malformed, wrong signature).\"\"\"\n    pass\nclass ExpiredTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has expired.\"\"\"\n    pass\nclass RevokedTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has been revoked.\"\"\"\n    pass\n# --- Token Creation ---",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "ExpiredTokenError",
        "kind": 6,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "class ExpiredTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has expired.\"\"\"\n    pass\nclass RevokedTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has been revoked.\"\"\"\n    pass\n# --- Token Creation ---\ndef _create_token(\n    data: Dict[str, Any],\n    expires_delta: timedelta,",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "RevokedTokenError",
        "kind": 6,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "class RevokedTokenError(InvalidTokenError):\n    \"\"\"Raised when a token has been revoked.\"\"\"\n    pass\n# --- Token Creation ---\ndef _create_token(\n    data: Dict[str, Any],\n    expires_delta: timedelta,\n    token_type: str = \"access\"\n) -> str:\n    \"\"\"",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "create_access_token",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def create_access_token(subject: Union[str, Any], additional_claims: Optional[Dict[str, Any]] = None) -> str:\n    \"\"\"\n    Creates an access token.\n    :param subject: Identifier for the token subject (e.g., user ID, agent ID).\n    :param additional_claims: Optional dictionary of additional claims to include.\n    :return: Encoded JWT string.\n    \"\"\"\n    if additional_claims is None:\n        additional_claims = {}\n    jwt_cfg = get_config().jwt",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "create_refresh_token",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def create_refresh_token(subject: Union[str, Any]) -> str:\n    \"\"\"\n    Creates a refresh token.\n    :param subject: Identifier for the token subject (e.g., user ID, agent ID).\n    :return: Encoded JWT string.\n    \"\"\"\n    jwt_cfg = get_config().jwt\n    expires_delta = timedelta(days=jwt_cfg.refresh_token_expire_days)\n    data_to_encode = {\"sub\": str(subject)}\n    # Refresh tokens typically have fewer claims and longer expiry",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "decode_token",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def decode_token(token: str) -> Dict[str, Any]:\n    \"\"\"\n    Decodes a JWT.\n    Raises InvalidTokenError or ExpiredTokenError on failure.\n    :param token: The JWT string to decode.\n    :return: The decoded payload as a dictionary.\n    :raises MissingTokenError: If the token is None or empty.\n    :raises ExpiredTokenError: If the token has expired.\n    :raises InvalidTokenError: If the token is malformed, has an invalid signature, or other JWT errors.\n    :raises RevokedTokenError: If the token is in the revocation list.",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "validate_token",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def validate_token(token: str, expected_token_type: Optional[str] = \"access\") -> Dict[str, Any]:\n    \"\"\"\n    Validates a token and checks its type.\n    :param token: The JWT string to validate.\n    :param expected_token_type: The expected type of the token (e.g., \"access\", \"refresh\").\n                                If None, type check is skipped.\n    :return: The decoded payload if the token is valid.\n    :raises InvalidTokenError: If the token type does not match or other validation issues.\n    \"\"\"\n    payload = decode_token(token) # This already handles expiry, signature, etc.",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "revoke_token",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def revoke_token(token_jti_or_full_token: str) -> None:\n    \"\"\"\n    Adds a token's JTI (JWT ID) or the full token string to the in-memory revocation list.\n    NOTE: This is a very basic in-memory revocation. Not suitable for production\n    without a persistent and shared revocation list (e.g., Redis, database).\n    \"\"\"\n    _revoked_tokens_store.add(token_jti_or_full_token)\ndef is_token_revoked(token_jti_or_full_token: str) -> bool:\n    \"\"\"Checks if a token (by JTI or full string) is in the in-memory revocation list.\"\"\"\n    return token_jti_or_full_token in _revoked_tokens_store",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "is_token_revoked",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def is_token_revoked(token_jti_or_full_token: str) -> bool:\n    \"\"\"Checks if a token (by JTI or full string) is in the in-memory revocation list.\"\"\"\n    return token_jti_or_full_token in _revoked_tokens_store\ndef clear_revoked_tokens_store() -> None:\n    \"\"\"Clears all tokens from the in-memory revocation list. Useful for testing.\"\"\"\n    _revoked_tokens_store.clear()\nif __name__ == \"__main__\":\n    # Basic usage example (primarily for quick testing during development)\n    # This will use the configuration loading mechanism (dummy files created in config.py's main)\n    # Ensure config is loaded (normally happens on first get_config() call)",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "clear_revoked_tokens_store",
        "kind": 2,
        "importPath": "src.aphelion.auth.jwt",
        "description": "src.aphelion.auth.jwt",
        "peekOfCode": "def clear_revoked_tokens_store() -> None:\n    \"\"\"Clears all tokens from the in-memory revocation list. Useful for testing.\"\"\"\n    _revoked_tokens_store.clear()\nif __name__ == \"__main__\":\n    # Basic usage example (primarily for quick testing during development)\n    # This will use the configuration loading mechanism (dummy files created in config.py's main)\n    # Ensure config is loaded (normally happens on first get_config() call)\n    # For this main block, let's explicitly load a test config if needed,\n    # or rely on the default loading mechanism.\n    # For jwt.py's own __main__, it's better if it can run somewhat independently",
        "detail": "src.aphelion.auth.jwt",
        "documentation": {}
    },
    {
        "label": "JWTConfigModel",
        "kind": 6,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "class JWTConfigModel(BaseModel):\n    \"\"\"Configuration for JWT generation and validation.\"\"\"\n    secret_key: SecretStr = Field(default_factory=lambda: SecretStr(\"your-default-super-secret-key-please-change\"))\n    algorithm: str = Field(default=\"HS256\")\n    access_token_expire_minutes: int = Field(default=30)\n    refresh_token_expire_days: int = Field(default=7)\n    # Placeholder for a more robust revocation list mechanism.\n    # This might not be directly configured via YAML/env for a simple set.\n    # It's more of a runtime state that might be backed by Redis/DB.\n    # For now, keeping it out of direct config loading, will be managed by auth module.",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "LoggingConfigModel",
        "kind": 6,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "class LoggingConfigModel(BaseModel):\n    \"\"\"Configuration for logging.\"\"\"\n    level: str = Field(default=\"INFO\")\n    file: Optional[Path] = Field(default=None) # e.g., BASE_DIR / \"logs\" / \"aphelion.log\"\n    # Example: format: str = Field(default=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n    @field_validator('level')\n    @classmethod\n    def valid_log_level(cls, value: str) -> str:\n        supported_levels = {\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"}\n        if value.upper() not in supported_levels:",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "AppConfigModel",
        "kind": 6,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "class AppConfigModel(BaseSettings):\n    \"\"\"\n    Main application settings model.\n    Loads settings from environment variables, .env files, and YAML files.\n    Environment variables take precedence.\n    \"\"\"\n    model_config = SettingsConfigDict(\n        env_prefix='APHELION_',  # Environment variables should be prefixed (e.g., APHELION_JWT__SECRET_KEY)\n        env_nested_delimiter='__', # For nested models like JWTConfigModel\n        env_file=BASE_DIR / '.env',       # Load from .env file if present",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "get_config",
        "kind": 2,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "def get_config(config_file_path: Optional[Union[str, Path]] = None) -> AppConfigModel:\n    \"\"\"\n    Retrieves the global configuration instance.\n    Loads it if it hasn't been loaded yet.\n    Allows specifying a custom config file path for the initial load.\n    \"\"\"\n    global _app_config\n    if _app_config is None:\n        # Determine the config file to use\n        # Env var APHELION_CONFIG_FILE can override the default path",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent.parent # Project root\nDEFAULT_CONFIG_FILE = BASE_DIR / \"config\" / \"aphelion_config.yaml\"\n# --- Pydantic Models for Configuration Sections ---\nclass JWTConfigModel(BaseModel):\n    \"\"\"Configuration for JWT generation and validation.\"\"\"\n    secret_key: SecretStr = Field(default_factory=lambda: SecretStr(\"your-default-super-secret-key-please-change\"))\n    algorithm: str = Field(default=\"HS256\")\n    access_token_expire_minutes: int = Field(default=30)\n    refresh_token_expire_days: int = Field(default=7)\n    # Placeholder for a more robust revocation list mechanism.",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_FILE",
        "kind": 5,
        "importPath": "src.aphelion.config",
        "description": "src.aphelion.config",
        "peekOfCode": "DEFAULT_CONFIG_FILE = BASE_DIR / \"config\" / \"aphelion_config.yaml\"\n# --- Pydantic Models for Configuration Sections ---\nclass JWTConfigModel(BaseModel):\n    \"\"\"Configuration for JWT generation and validation.\"\"\"\n    secret_key: SecretStr = Field(default_factory=lambda: SecretStr(\"your-default-super-secret-key-please-change\"))\n    algorithm: str = Field(default=\"HS256\")\n    access_token_expire_minutes: int = Field(default=30)\n    refresh_token_expire_days: int = Field(default=7)\n    # Placeholder for a more robust revocation list mechanism.\n    # This might not be directly configured via YAML/env for a simple set.",
        "detail": "src.aphelion.config",
        "documentation": {}
    },
    {
        "label": "get_greeting",
        "kind": 2,
        "importPath": "src.aphelion.main",
        "description": "src.aphelion.main",
        "peekOfCode": "def get_greeting() -> str:\n    \"\"\"\n    Returns a simple greeting string.\n    This is a placeholder function.\n    \"\"\"\n    return \"Hello from Aphelion!\"\nif __name__ == \"__main__\":\n    print(get_greeting())",
        "detail": "src.aphelion.main",
        "documentation": {}
    },
    {
        "label": "mocked_jwt_config_model",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def mocked_jwt_config_model() -> JWTConfigModel:\n    \"\"\"Provides a consistent JWTConfigModel instance for tests.\"\"\"\n    return JWTConfigModel(\n        secret_key=DEFAULT_TEST_SECRET_KEY, # type: ignore [arg-type] # pydantic handles SecretStr\n        algorithm=\"HS256\",\n        access_token_expire_minutes=5,\n        refresh_token_expire_days=1,\n    )\n@pytest.fixture(autouse=True)\ndef mock_aphelion_config_for_jwt_tests(mocked_jwt_config_model: JWTConfigModel):",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "mock_aphelion_config_for_jwt_tests",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def mock_aphelion_config_for_jwt_tests(mocked_jwt_config_model: JWTConfigModel):\n    \"\"\"\n    Patches get_config() within the aphelion.auth.jwt module to return a\n    test-specific AppConfigModel containing the mocked_jwt_config_model.\n    Also clears the JWT revocation store before and after each test.\n    \"\"\"\n    clear_revoked_tokens_store() # Clear before test runs\n    # Create a full AppConfigModel instance, embedding the mocked JWT config\n    test_app_config = AppConfigModel(jwt=mocked_jwt_config_model)\n    # The crucial part is to patch 'get_config' in the *module where it's used* (aphelion.auth.jwt)",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_create_access_token_default_claims",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_create_access_token_default_claims():\n    token = create_access_token(subject=TEST_SUBJECT)\n    payload = decode_token(token) # Use internal decode for direct payload inspection\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"type\"] == \"access\"\n    assert \"exp\" in payload\n    assert \"iat\" in payload\n    assert \"iss\" in payload\n    assert payload[\"iss\"] == \"aphelion_security_framework\"\ndef test_create_access_token_with_additional_claims():",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_create_access_token_with_additional_claims",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_create_access_token_with_additional_claims():\n    token = create_access_token(subject=TEST_SUBJECT, additional_claims=TEST_ADDITIONAL_CLAIMS)\n    payload = decode_token(token)\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"role\"] == TEST_ADDITIONAL_CLAIMS[\"role\"]\n    assert payload[\"scope\"] == TEST_ADDITIONAL_CLAIMS[\"scope\"]\n    assert payload[\"type\"] == \"access\"\ndef test_create_refresh_token():\n    token = create_refresh_token(subject=TEST_SUBJECT)\n    payload = decode_token(token)",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_create_refresh_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_create_refresh_token():\n    token = create_refresh_token(subject=TEST_SUBJECT)\n    payload = decode_token(token)\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"type\"] == \"refresh\"\n    assert \"exp\" in payload\n    assert \"iat\" in payload\n    # Refresh tokens should not contain additional app-specific claims by default\n    assert \"role\" not in payload\ndef test_validate_valid_access_token():",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_valid_access_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_valid_access_token():\n    token = create_access_token(subject=TEST_SUBJECT, additional_claims=TEST_ADDITIONAL_CLAIMS)\n    payload = validate_token(token, expected_token_type=\"access\")\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"role\"] == TEST_ADDITIONAL_CLAIMS[\"role\"]\ndef test_validate_valid_refresh_token():\n    token = create_refresh_token(subject=TEST_SUBJECT)\n    payload = validate_token(token, expected_token_type=\"refresh\")\n    assert payload[\"sub\"] == TEST_SUBJECT\ndef test_validate_token_no_type_check():",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_valid_refresh_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_valid_refresh_token():\n    token = create_refresh_token(subject=TEST_SUBJECT)\n    payload = validate_token(token, expected_token_type=\"refresh\")\n    assert payload[\"sub\"] == TEST_SUBJECT\ndef test_validate_token_no_type_check():\n    token = create_access_token(subject=TEST_SUBJECT)\n    payload = validate_token(token, expected_token_type=None) # Skip type check\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"type\"] == \"access\"\ndef test_decode_expired_access_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_token_no_type_check",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_token_no_type_check():\n    token = create_access_token(subject=TEST_SUBJECT)\n    payload = validate_token(token, expected_token_type=None) # Skip type check\n    assert payload[\"sub\"] == TEST_SUBJECT\n    assert payload[\"type\"] == \"access\"\ndef test_decode_expired_access_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Override the global mock for this specific test to set a past expiry\n    expired_jwt_config = mocked_jwt_config_model.model_copy(update={\"access_token_expire_minutes\": -1})\n    expired_app_config = AppConfigModel(jwt=expired_jwt_config)\n    mock_aphelion_config_for_jwt_tests.return_value = expired_app_config",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_decode_expired_access_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_decode_expired_access_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Override the global mock for this specific test to set a past expiry\n    expired_jwt_config = mocked_jwt_config_model.model_copy(update={\"access_token_expire_minutes\": -1})\n    expired_app_config = AppConfigModel(jwt=expired_jwt_config)\n    mock_aphelion_config_for_jwt_tests.return_value = expired_app_config\n    token = create_access_token(subject=TEST_SUBJECT)\n    with pytest.raises(ExpiredTokenError):\n        decode_token(token)\ndef test_validate_expired_access_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Override the global mock for this specific test for very short expiry",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_expired_access_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_expired_access_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Override the global mock for this specific test for very short expiry\n    short_expiry_jwt_config = mocked_jwt_config_model.model_copy(\n        update={\"access_token_expire_minutes\": 1/6000} # Approx 0.01 seconds\n    )\n    short_expiry_app_config = AppConfigModel(jwt=short_expiry_jwt_config)\n    mock_aphelion_config_for_jwt_tests.return_value = short_expiry_app_config\n    token_short = create_access_token(subject=\"short_lived_user\")\n    time.sleep(0.1) # Wait for 0.1 seconds, should be enough for it to expire\n    with pytest.raises(ExpiredTokenError):",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_decode_invalid_signature_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_decode_invalid_signature_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Create a token with the current (mocked) key\n    token = create_access_token(subject=TEST_SUBJECT)\n    # Now, change the config that get_config() will return for the decode step\n    # Pydantic should convert the string \"completely-different-secret\" to SecretStr\n    # Explicitly create SecretStr for the update to be certain.\n    from pydantic import SecretStr\n    wrong_key_jwt_config = mocked_jwt_config_model.model_copy(\n        update={\"secret_key\": SecretStr(\"completely-different-secret\")}\n    )",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_invalid_signature_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_invalid_signature_token(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # Create a token with the current (mocked) key\n    token = create_access_token(subject=TEST_SUBJECT)\n    # Change the config for the validation step\n    from pydantic import SecretStr\n    another_wrong_key_jwt_config = mocked_jwt_config_model.model_copy(\n        update={\"secret_key\": SecretStr(\"another-wrong-secret\")}\n    )\n    another_wrong_key_app_config = AppConfigModel(jwt=another_wrong_key_jwt_config)\n    mock_aphelion_config_for_jwt_tests.return_value = another_wrong_key_app_config",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_decode_malformed_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_decode_malformed_token():\n    malformed_token = \"this.is.not.a.jwt\"\n    with pytest.raises(InvalidTokenError) as excinfo:\n        decode_token(malformed_token)\n    # Check that our wrapper exception is raised. The specific PyJWT internal error can vary.\n    assert \"Token is invalid\" in str(excinfo.value)\ndef test_validate_malformed_token():\n    malformed_token = \"this.is.still.not.a.jwt\"\n    with pytest.raises(InvalidTokenError):\n        validate_token(malformed_token)",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_malformed_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_malformed_token():\n    malformed_token = \"this.is.still.not.a.jwt\"\n    with pytest.raises(InvalidTokenError):\n        validate_token(malformed_token)\ndef test_decode_missing_token():\n    with pytest.raises(MissingTokenError):\n        decode_token(\"\")\n    with pytest.raises(MissingTokenError):\n        decode_token(None) # type: ignore\ndef test_validate_missing_token():",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_decode_missing_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_decode_missing_token():\n    with pytest.raises(MissingTokenError):\n        decode_token(\"\")\n    with pytest.raises(MissingTokenError):\n        decode_token(None) # type: ignore\ndef test_validate_missing_token():\n    with pytest.raises(MissingTokenError):\n        validate_token(\"\")\n    with pytest.raises(MissingTokenError):\n        validate_token(None) # type: ignore",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_missing_token",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_missing_token():\n    with pytest.raises(MissingTokenError):\n        validate_token(\"\")\n    with pytest.raises(MissingTokenError):\n        validate_token(None) # type: ignore\ndef test_validate_wrong_token_type():\n    access_token = create_access_token(subject=TEST_SUBJECT)\n    with pytest.raises(InvalidTokenError) as excinfo:\n        validate_token(access_token, expected_token_type=\"refresh\")\n    assert \"Invalid token type. Expected 'refresh', got 'access'\" in str(excinfo.value)",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_validate_wrong_token_type",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_validate_wrong_token_type():\n    access_token = create_access_token(subject=TEST_SUBJECT)\n    with pytest.raises(InvalidTokenError) as excinfo:\n        validate_token(access_token, expected_token_type=\"refresh\")\n    assert \"Invalid token type. Expected 'refresh', got 'access'\" in str(excinfo.value)\n    refresh_token = create_refresh_token(subject=TEST_SUBJECT)\n    with pytest.raises(InvalidTokenError) as excinfo:\n        validate_token(refresh_token, expected_token_type=\"access\")\n    assert \"Invalid token type. Expected 'access', got 'refresh'\" in str(excinfo.value)\n# Removed test_create_token_missing_subject because create_access_token(subject=None)",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_token_revocation",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_token_revocation(): # Removed setup_jwt_config: JWTConfig argument\n    token_to_revoke1 = create_access_token(\"user_to_be_revoked_1\")\n    token_to_revoke2 = create_refresh_token(\"user_to_be_revoked_2\")\n    token_not_revoked = create_access_token(\"user_not_revoked\")\n    # Ensure tokens are initially valid and not revoked\n    assert is_token_revoked(token_to_revoke1) is False\n    validate_token(token_to_revoke1)\n    assert is_token_revoked(token_to_revoke2) is False\n    validate_token(token_to_revoke2, expected_token_type=\"refresh\")\n    assert is_token_revoked(token_not_revoked) is False",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_jwt_behavior_with_changed_config_algorithm",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_jwt_behavior_with_changed_config_algorithm(\n    mock_aphelion_config_for_jwt_tests: MagicMock,\n    mocked_jwt_config_model: JWTConfigModel\n):\n    # 1. Create token with default HS256 algorithm (from main fixture)\n    token_hs256 = create_access_token(TEST_SUBJECT)\n    # Validate it works with HS256\n    payload_hs256 = validate_token(token_hs256)\n    assert payload_hs256[\"sub\"] == TEST_SUBJECT\n    # 2. Change the live JWT config to use HS512 for subsequent operations",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_token_nbf_claim",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_token_nbf_claim(mock_aphelion_config_for_jwt_tests: MagicMock, mocked_jwt_config_model: JWTConfigModel):\n    # \"nbf\" (Not Before) claim\n    # For this, we need to inject 'nbf' into the token creation.\n    # Let's assume _create_token could be extended or we craft it manually.\n    nbf_time = int(time.time()) + 300  # Token not valid for 300 seconds\n    iat_time = int(time.time())\n    # Use the mocked_jwt_config_model passed to the test\n    exp_time = iat_time + mocked_jwt_config_model.access_token_expire_minutes * 60\n    custom_payload = {\n        \"sub\": TEST_SUBJECT,",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "test_default_test_secret_is_not_app_placeholder",
        "kind": 2,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "def test_default_test_secret_is_not_app_placeholder(mock_aphelion_config_for_jwt_tests: MagicMock):\n    # The mock_aphelion_config_for_jwt_tests fixture sets up get_config() to return\n    # an AppConfigModel containing a JWTConfigModel with DEFAULT_TEST_SECRET_KEY.\n    # We access this through the mock of get_config if we want to inspect its return_value,\n    # or by calling get_config() itself (which will return the mocked value).\n    from aphelion.auth.jwt import get_config # Import it here to ensure it's the one from jwt module\n    current_jwt_config = get_config().jwt # This will use the mocked get_config\n    assert current_jwt_config.secret_key.get_secret_value() == DEFAULT_TEST_SECRET_KEY\n    assert current_jwt_config.secret_key.get_secret_value() != \"your-default-super-secret-key-please-change\"\n    # Also check the algorithm to be sure we have the right test config",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "TEST_SUBJECT",
        "kind": 5,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "TEST_SUBJECT = \"test_user_123\"\nTEST_ADDITIONAL_CLAIMS = {\"role\": \"tester\", \"scope\": \"read:data\"}\nDEFAULT_TEST_SECRET_KEY = \"test-secret-key-for-pytest\"\n@pytest.fixture\ndef mocked_jwt_config_model() -> JWTConfigModel:\n    \"\"\"Provides a consistent JWTConfigModel instance for tests.\"\"\"\n    return JWTConfigModel(\n        secret_key=DEFAULT_TEST_SECRET_KEY, # type: ignore [arg-type] # pydantic handles SecretStr\n        algorithm=\"HS256\",\n        access_token_expire_minutes=5,",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "TEST_ADDITIONAL_CLAIMS",
        "kind": 5,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "TEST_ADDITIONAL_CLAIMS = {\"role\": \"tester\", \"scope\": \"read:data\"}\nDEFAULT_TEST_SECRET_KEY = \"test-secret-key-for-pytest\"\n@pytest.fixture\ndef mocked_jwt_config_model() -> JWTConfigModel:\n    \"\"\"Provides a consistent JWTConfigModel instance for tests.\"\"\"\n    return JWTConfigModel(\n        secret_key=DEFAULT_TEST_SECRET_KEY, # type: ignore [arg-type] # pydantic handles SecretStr\n        algorithm=\"HS256\",\n        access_token_expire_minutes=5,\n        refresh_token_expire_days=1,",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "DEFAULT_TEST_SECRET_KEY",
        "kind": 5,
        "importPath": "tests.auth.test_jwt",
        "description": "tests.auth.test_jwt",
        "peekOfCode": "DEFAULT_TEST_SECRET_KEY = \"test-secret-key-for-pytest\"\n@pytest.fixture\ndef mocked_jwt_config_model() -> JWTConfigModel:\n    \"\"\"Provides a consistent JWTConfigModel instance for tests.\"\"\"\n    return JWTConfigModel(\n        secret_key=DEFAULT_TEST_SECRET_KEY, # type: ignore [arg-type] # pydantic handles SecretStr\n        algorithm=\"HS256\",\n        access_token_expire_minutes=5,\n        refresh_token_expire_days=1,\n    )",
        "detail": "tests.auth.test_jwt",
        "documentation": {}
    },
    {
        "label": "GIVEN_FUNCTION_TO_FUZZ_DOES_NOT_YET_EXIST_SO_THIS_IS_A_PLACEHOLDER",
        "kind": 2,
        "importPath": "tests.security.test_fuzzing_examples",
        "description": "tests.security.test_fuzzing_examples",
        "peekOfCode": "def GIVEN_FUNCTION_TO_FUZZ_DOES_NOT_YET_EXIST_SO_THIS_IS_A_PLACEHOLDER(input_string: str) -> str:\n    \"\"\"\n    A placeholder function. In a real scenario, this would be a function\n    from the main codebase that processes input and should be resilient.\n    Example: It might try to parse a complex string or sanitize it.\n    \"\"\"\n    if input_string is None:\n        raise TypeError(\"Input cannot be None\")\n    # Simple example: just returns the string, or a modified version.\n    # A real function might have complex logic prone to errors with weird inputs.",
        "detail": "tests.security.test_fuzzing_examples",
        "documentation": {}
    },
    {
        "label": "test_placeholder_fuzz_example",
        "kind": 2,
        "importPath": "tests.security.test_fuzzing_examples",
        "description": "tests.security.test_fuzzing_examples",
        "peekOfCode": "def test_placeholder_fuzz_example(sample_text: str):\n    \"\"\"\n    Example of a Hypothesis test. This would target a real function\n    in the Aphelion framework that needs to be robust against varied string inputs.\n    \"\"\"\n    try:\n        result = GIVEN_FUNCTION_TO_FUZZ_DOES_NOT_YET_EXIST_SO_THIS_IS_A_PLACEHOLDER(sample_text)\n        assert isinstance(result, str)\n        if sample_text is not None: # Guarding due to st.text() possibly generating complex objects if not careful\n            assert sample_text in result",
        "detail": "tests.security.test_fuzzing_examples",
        "documentation": {}
    },
    {
        "label": "simple_string_processor",
        "kind": 2,
        "importPath": "tests.security.test_fuzzing_examples",
        "description": "tests.security.test_fuzzing_examples",
        "peekOfCode": "def simple_string_processor(s: str) -> str:\n    if not isinstance(s, str):\n        # This case should ideally not be hit if st.text() is used,\n        # as it generates strings. But good for robustness.\n        raise TypeError(\"Input must be a string\")\n    return s.lower() # Example processing\n@settings(suppress_health_check=[HealthCheck.too_slow], deadline=None)\n@given(st.text())\ndef test_simple_string_processor_does_not_crash(text_input: str):\n    \"\"\"",
        "detail": "tests.security.test_fuzzing_examples",
        "documentation": {}
    },
    {
        "label": "test_simple_string_processor_does_not_crash",
        "kind": 2,
        "importPath": "tests.security.test_fuzzing_examples",
        "description": "tests.security.test_fuzzing_examples",
        "peekOfCode": "def test_simple_string_processor_does_not_crash(text_input: str):\n    \"\"\"\n    Tests that simple_string_processor runs without unhandled exceptions\n    for any text input provided by Hypothesis.\n    \"\"\"\n    processed_text = simple_string_processor(text_input)\n    assert isinstance(processed_text, str)\n    assert processed_text == text_input.lower()\n@settings(suppress_health_check=[HealthCheck.too_slow], deadline=None)\n@given(st.integers())",
        "detail": "tests.security.test_fuzzing_examples",
        "documentation": {}
    },
    {
        "label": "test_another_placeholder_fuzz_integers",
        "kind": 2,
        "importPath": "tests.security.test_fuzzing_examples",
        "description": "tests.security.test_fuzzing_examples",
        "peekOfCode": "def test_another_placeholder_fuzz_integers(num_input: int):\n    \"\"\"Another example with integers.\"\"\"\n    assert isinstance(num_input, int)\n    # In a real test, call a function with num_input and assert properties.\n    pass",
        "detail": "tests.security.test_fuzzing_examples",
        "documentation": {}
    },
    {
        "label": "setup_module",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def setup_module(module):\n    \"\"\"Save original environment variables that might be modified by tests.\"\"\"\n    vars_to_save = [\n        \"APHELION_APP_NAME\",\n        \"APHELION_DEBUG_MODE\",\n        \"APHELION_JWT__SECRET_KEY\",\n        \"APHELION_JWT__ALGORITHM\",\n        \"APHELION_JWT__ACCESS_TOKEN_EXPIRE_MINUTES\",\n        \"APHELION_LOGGING__LEVEL\",\n        \"APHELION_CONFIG_FILE\" # If used to redirect config loading globally",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "teardown_module",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def teardown_module(module):\n    \"\"\"Restore original environment variables.\"\"\"\n    for var_name, value in ORIGINAL_ENV_VARS.items():\n        os.environ[var_name] = value\n    # Clean up any env vars set by tests that weren't originally there\n    test_set_vars = [\n        \"APHELION_APP_NAME\", \"APHELION_DEBUG_MODE\", \"APHELION_JWT__SECRET_KEY\",\n        \"APHELION_JWT__ALGORITHM\", \"APHELION_JWT__ACCESS_TOKEN_EXPIRE_MINUTES\",\n        \"APHELION_LOGGING__LEVEL\", \"APHELION_CONFIG_FILE\"\n    ]",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "reset_global_config_and_env",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def reset_global_config_and_env(monkeypatch):\n    \"\"\"\n    Resets the global _app_config in aphelion.config to None before each test,\n    and cleans up specific environment variables set by tests.\n    \"\"\"\n    # Reset the internal _app_config variable in the config module\n    # This forces get_config() to reload in each test if called.\n    with patch('aphelion.config._app_config', None):\n        # Clean specific env vars using monkeypatch for safety\n        env_vars_to_clear = [",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "dummy_config_yaml_file",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def dummy_config_yaml_file(tmp_path: Path) -> Path:\n    \"\"\"Creates a temporary YAML config file for testing.\"\"\"\n    config_content = {\n        \"app_name\": \"Test App YAML\",\n        \"debug_mode\": True,\n        \"jwt\": {\n            \"secret_key\": \"yaml_secret\",\n            \"algorithm\": \"HS512\",\n            \"access_token_expire_minutes\": 60,\n        },",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_defaults_no_file_no_env",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_load_defaults_no_file_no_env():\n    \"\"\"Test that default values are loaded if no config file or env vars are set.\"\"\"\n    # Ensure no config file is pointed to by env var for this test\n    if \"APHELION_CONFIG_FILE\" in os.environ:\n        del os.environ[\"APHELION_CONFIG_FILE\"]\n    # Patch DEFAULT_CONFIG_FILE to point to a non-existent file for this test\n    with patch('aphelion.config.DEFAULT_CONFIG_FILE', BASE_DIR_FOR_TESTS / \"non_existent_config.yaml\"):\n        config = get_config()\n    assert config.app_name == \"Aphelion Security Framework\" # Default\n    assert config.debug_mode is False # Default",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_from_yaml_file",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_load_from_yaml_file(dummy_config_yaml_file: Path):\n    \"\"\"Test loading configuration purely from a YAML file.\"\"\"\n    config = get_config(config_file_path=dummy_config_yaml_file)\n    assert config.app_name == \"Test App YAML\"\n    assert config.debug_mode is True\n    assert config.jwt.secret_key.get_secret_value() == \"yaml_secret\"\n    assert config.jwt.algorithm == \"HS512\"\n    assert config.jwt.access_token_expire_minutes == 60\n    assert config.logging.level == \"DEBUG\"\n    assert str(config.logging.file) == \"/tmp/test_app.log\" # Path objects comparison",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_from_env_vars_override_yaml",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_load_from_env_vars_override_yaml(dummy_config_yaml_file: Path, monkeypatch):\n    \"\"\"Test that environment variables override YAML file settings.\"\"\"\n    monkeypatch.setenv(\"APHELION_APP_NAME\", \"Test App ENV\")\n    monkeypatch.setenv(\"APHELION_DEBUG_MODE\", \"false\") # Note: pydantic-settings handles bool conversion\n    monkeypatch.setenv(\"APHELION_JWT__SECRET_KEY\", \"env_secret\")\n    monkeypatch.setenv(\"APHELION_JWT__ALGORITHM\", \"RS256\")\n    monkeypatch.setenv(\"APHELION_LOGGING__LEVEL\", \"ERROR\")\n    config = get_config(config_file_path=dummy_config_yaml_file)\n    assert config.app_name == \"Test App ENV\"\n    assert config.debug_mode is False # Pydantic converts \"false\"",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_from_env_vars_only",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_load_from_env_vars_only(monkeypatch):\n    \"\"\"Test loading configuration purely from environment variables (no YAML file).\"\"\"\n    monkeypatch.setenv(\"APHELION_APP_NAME\", \"ENV App Only\")\n    monkeypatch.setenv(\"APHELION_DEBUG_MODE\", \"true\")\n    monkeypatch.setenv(\"APHELION_JWT__SECRET_KEY\", \"env_only_secret\")\n    monkeypatch.setenv(\"APHELION_JWT__ALGORITHM\", \"ES256\")\n    monkeypatch.setenv(\"APHELION_JWT__ACCESS_TOKEN_EXPIRE_MINUTES\", \"15\")\n    monkeypatch.setenv(\"APHELION_LOGGING__LEVEL\", \"CRITICAL\")\n    # Patch DEFAULT_CONFIG_FILE to a non-existent one to ensure no YAML is loaded\n    with patch('aphelion.config.DEFAULT_CONFIG_FILE', BASE_DIR_FOR_TESTS / \"no_such_config.yaml\"):",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_jwt_config_invalid_algorithm_in_yaml",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_jwt_config_invalid_algorithm_in_yaml(tmp_path: Path):\n    \"\"\"Test validation error for unsupported JWT algorithm in YAML.\"\"\"\n    config_content = {\"jwt\": {\"algorithm\": \"INVALID_ALGO\"}}\n    yaml_file = tmp_path / \"invalid_algo.yaml\"\n    with open(yaml_file, 'w') as f:\n        yaml.dump(config_content, f)\n    with pytest.raises(ValidationError) as excinfo:\n        get_config(config_file_path=yaml_file)\n    assert \"Unsupported JWT algorithm: INVALID_ALGO\" in str(excinfo.value)\ndef test_logging_config_invalid_level_in_env(monkeypatch):",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_logging_config_invalid_level_in_env",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_logging_config_invalid_level_in_env(monkeypatch):\n    \"\"\"Test validation error for invalid logging level from environment.\"\"\"\n    monkeypatch.setenv(\"APHELION_LOGGING__LEVEL\", \"SUPER_VERBOSE\")\n    with patch('aphelion.config.DEFAULT_CONFIG_FILE', BASE_DIR_FOR_TESTS / \"no_such_config.yaml\"):\n        with pytest.raises(ValidationError) as excinfo:\n            get_config()\n    assert \"Invalid log level: SUPER_VERBOSE\" in str(excinfo.value)\ndef test_secret_str_hides_secret_in_repr():\n    \"\"\"Test that SecretStr correctly hides the secret key in representations.\"\"\"\n    config = AppConfigModel(jwt=JWTConfigModel(secret_key=\"my_very_secret_key\")) # type: ignore",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_secret_str_hides_secret_in_repr",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_secret_str_hides_secret_in_repr():\n    \"\"\"Test that SecretStr correctly hides the secret key in representations.\"\"\"\n    config = AppConfigModel(jwt=JWTConfigModel(secret_key=\"my_very_secret_key\")) # type: ignore\n    assert \"my_very_secret_key\" not in repr(config.jwt.secret_key)\n    assert \"**********\" in repr(config.jwt.secret_key)\n    assert config.jwt.secret_key.get_secret_value() == \"my_very_secret_key\"\ndef test_config_file_env_variable_precedence(tmp_path: Path, monkeypatch):\n    \"\"\"Test APHELION_CONFIG_FILE environment variable overrides default path.\"\"\"\n    default_yaml_content = {\"app_name\": \"Default YAML Name\"}\n    default_config_dir = tmp_path / \"default_config_dir\"",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_config_file_env_variable_precedence",
        "kind": 2,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "def test_config_file_env_variable_precedence(tmp_path: Path, monkeypatch):\n    \"\"\"Test APHELION_CONFIG_FILE environment variable overrides default path.\"\"\"\n    default_yaml_content = {\"app_name\": \"Default YAML Name\"}\n    default_config_dir = tmp_path / \"default_config_dir\"\n    default_config_dir.mkdir()\n    default_yaml_file = default_config_dir / \"aphelion_config.yaml\" # Simulates DEFAULT_CONFIG_FILE\n    with open(default_yaml_file, 'w') as f:\n        yaml.dump(default_yaml_content, f)\n    custom_yaml_content = {\"app_name\": \"Custom YAML Name via ENV Var\"}\n    custom_yaml_file = tmp_path / \"custom_path.yaml\"",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "BASE_DIR_FOR_TESTS",
        "kind": 5,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "BASE_DIR_FOR_TESTS = Path(__file__).resolve().parent.parent # Project root for test context\n# Store original env vars to restore them after tests\nORIGINAL_ENV_VARS = {}\ndef setup_module(module):\n    \"\"\"Save original environment variables that might be modified by tests.\"\"\"\n    vars_to_save = [\n        \"APHELION_APP_NAME\",\n        \"APHELION_DEBUG_MODE\",\n        \"APHELION_JWT__SECRET_KEY\",\n        \"APHELION_JWT__ALGORITHM\",",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "ORIGINAL_ENV_VARS",
        "kind": 5,
        "importPath": "tests.test_config",
        "description": "tests.test_config",
        "peekOfCode": "ORIGINAL_ENV_VARS = {}\ndef setup_module(module):\n    \"\"\"Save original environment variables that might be modified by tests.\"\"\"\n    vars_to_save = [\n        \"APHELION_APP_NAME\",\n        \"APHELION_DEBUG_MODE\",\n        \"APHELION_JWT__SECRET_KEY\",\n        \"APHELION_JWT__ALGORITHM\",\n        \"APHELION_JWT__ACCESS_TOKEN_EXPIRE_MINUTES\",\n        \"APHELION_LOGGING__LEVEL\",",
        "detail": "tests.test_config",
        "documentation": {}
    },
    {
        "label": "test_get_greeting",
        "kind": 2,
        "importPath": "tests.test_main",
        "description": "tests.test_main",
        "peekOfCode": "def test_get_greeting():\n    \"\"\"\n    Tests the get_greeting function from main.py.\n    \"\"\"\n    assert get_greeting() == \"Hello from Aphelion!\"\ndef test_placeholder_true():\n    \"\"\"\n    A placeholder test that always passes.\n    Can be removed or replaced as actual tests are added.\n    \"\"\"",
        "detail": "tests.test_main",
        "documentation": {}
    },
    {
        "label": "test_placeholder_true",
        "kind": 2,
        "importPath": "tests.test_main",
        "description": "tests.test_main",
        "peekOfCode": "def test_placeholder_true():\n    \"\"\"\n    A placeholder test that always passes.\n    Can be removed or replaced as actual tests are added.\n    \"\"\"\n    assert True is True",
        "detail": "tests.test_main",
        "documentation": {}
    }
]